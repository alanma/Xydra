maintain a list of local commands
  to not loose the forced/safe information
  
sync:
  store.executeCommandsAndGetEvents
  process command results
    for each local command:
      if processed: fine
        fire sync-success event later
        remember successful revNr
      if failed: needs to be escalated
        fire sync-failed event later
        @@ calculate anti-event to command to bring local
        ... state in sync with server state
        enqueue this anti-event
  process remote events (mix of truly remote events + events caused by commands)
    if eventNo == successRevNr 
      no event to be send
    else
      enqueue event to be sent
      
NOW:

  remove listeners that belong to deleted entities
  
  fire sync events
    sync-failed events: app needs to preserve state info NOW before
    ...change-anti events wipe them out

  fire anti-events
  fire other change events:
    for each transaction:	
      fire atomic change events
      fire transaction change events      
    for atomic event:
      just fire it            
      
________________


mergeFieldEvents, e.g. remove value+add value=change value

cleanEvents: remove events that cancel each other out

sendEvents: from internal queue to event fires

( ) MemoryLocalChange.updateCommand: move safe rev higher

persist & respawn

execute transaction
  lock root
  work on delta
  if ok, manifest changes in
    state
    changelog
    local commands
    event listenrs

replayCommand

replayEvent

rollback

rollbackEvent

which actor to use (+ passwd)

how/when to fix safe commands? ever?
Synchronizer.fixCommands -- adapt safe commands that rely on each other, not on remote changes

----

server:
list of events since syncRev

client: list of LocalChanges since syncRev

save remote events as they are

analyse local events to find out the delta between our local world view
...and the remote world view

... for sync events: consider as success if they happened ever in any order	

...send out change events about the difference

task: merge

idea:
- minimize LocalChanges: remove those that have no effect / are not not marked as "saved" versions
- minimize incoming changes? => save null-changes in changelog



 * Different from a {@link ChangedModel}, this class e.g., can keep fields even
 * if its object is removed. The state is stored as an event storage.
 * 
 * Revision numbers of incoming events are used.
 * 
 * Implementation idea:
 * 
 * Base case: Reverse all local events in inverse order; then apply all remote
 * events.
 * 
 * Smarter: If the same event has happened locally, do not reverse it and do not
 * apply it later.
 * 
 * Also smarter: Dont use redundant local events
 * 
 * Also smarter: If remote events cancel each other, also don't send them.
 * 
 * Order of events between entities does not matter, we can replay in this
 * order: remove value, remove field, remove object, remove model, add model,
 * add object, add field, add/change value. But we can also use the order of
 * local and remote events.
 * 
 * What is a good data structure to detect and eliminate duplicate events? What
 * uses not much memory, runs in O(n*log(n)), needs few passes over the data?
 * 
 * Given: remoteEvents as an array, localEvents as an iterator.
 * 
 * Data structure 'UniqueEntityEvents': EntityType -> ChangedEntityAddress ->
 * Event
 * 
 * (1) Add all localEvents to a UniqueEntityEvents, getting rid of duplicate
 * events per entity
 * 
 * (2) Add all remoteEvents to another UniqueEntityEvents, getting rid of
 * duplicate events per entity
 * 
 * (3) Create a third UniqueEntityEvents by merging localEvents & remoteEvents
 * on a per-entity-basis
 * 
 * (4) Retrieve merged events in remove-before-add and
 * repo-model-object-field-order.
 * 
 * Analysis: Let R be number of remote and L be number of local events.
 * 
 * Then: (1) O(L), (2) O(R), (3) O(L+R), (4) O(L+R) => 3 L + 3 R


      